{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3326124",
   "metadata": {},
   "source": [
    "# Project 8: Deploy a model with a big data architecture in AWS\n",
    "\n",
    "*Pierre-Eloi Ragetly*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525edd1b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Create-a-file-with-all-picture's-path\" data-toc-modified-id=\"Create-a-file-with-all-picture's-path-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Create a file with all picture's path</a></span></li><li><span><a href=\"#Create-a-Spark-DataFrame-with-a-Path-column\" data-toc-modified-id=\"Create-a-Spark-DataFrame-with-a-Path-column-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Create a Spark DataFrame with a Path column</a></span></li><li><span><a href=\"#Create-a-Category-column\" data-toc-modified-id=\"Create-a-Category-column-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create a Category column</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93782b02",
   "metadata": {},
   "source": [
    "## Create a file with all picture's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76684da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:16.311404Z",
     "start_time": "2022-10-06T13:38:16.298506Z"
    }
   },
   "outputs": [],
   "source": [
    "# File system management\n",
    "import os\n",
    "\n",
    "root_path = 'dataset/fruits-360_dataset/fruits-360'\n",
    "train_path = os.path.join(root_path, 'Training')\n",
    "test_path = os.path.join(root_path, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3fe957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:16.316903Z",
     "start_time": "2022-10-06T13:38:16.313495Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_files_paths(path, text_name):\n",
    "    \"\"\"Extract all files paths and save them into a text file.\"\"\"\n",
    "    list_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if not f[0] == '.':\n",
    "                list_files.append(os.path.join(root, f))\n",
    "    with open(text_name, 'w') as f:\n",
    "        f.write('\\n'.join(list_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16bdee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:16.855776Z",
     "start_time": "2022-10-06T13:38:16.318692Z"
    }
   },
   "outputs": [],
   "source": [
    "get_files_paths(train_path, 'dataset/train_files.txt')\n",
    "get_files_paths(test_path, 'dataset/test_files.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5425da7",
   "metadata": {},
   "source": [
    "## Create a Spark DataFrame with a Path column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f635150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:19.735045Z",
     "start_time": "2022-10-06T13:38:16.860341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 15:38:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5da06b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:19.742179Z",
     "start_time": "2022-10-06T13:38:19.739080Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_files_paths(path):\n",
    "    \"\"\"Load files paths into a Spark DataFrame\"\"\"\n",
    "    rdd = sc.textFile(path)\\\n",
    "            .map(lambda line: Row(path=line))\n",
    "    return spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9d2269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:23.575675Z",
     "start_time": "2022-10-06T13:38:19.745801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train = load_files_paths('dataset/train_files.txt')\n",
    "test = load_files_paths('dataset/train_files.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a10daea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:23.608086Z",
     "start_time": "2022-10-06T13:38:23.577385Z"
    }
   },
   "outputs": [],
   "source": [
    "data = train.union(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82aecfe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:28.332050Z",
     "start_time": "2022-10-06T13:38:23.611851Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 15:38:28 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 2 (TID 2): Attempting to kill Python Worker\n",
      "+---------------------------------------------------------------------+\n",
      "|path                                                                 |\n",
      "+---------------------------------------------------------------------+\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/r_236_100.jpg|\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/247_100.jpg  |\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/257_100.jpg  |\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/r_78_100.jpg |\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/r_68_100.jpg |\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/r_150_100.jpg|\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/r_140_100.jpg|\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/131_100.jpg  |\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/198_100.jpg  |\n",
      "|dataset/fruits-360_dataset/fruits-360/Training/Tomato 4/18_100.jpg   |\n",
      "+---------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data.limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb81a0",
   "metadata": {},
   "source": [
    "## Create a Category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59cb525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:28.342643Z",
     "start_time": "2022-10-06T13:38:28.334737Z"
    }
   },
   "outputs": [],
   "source": [
    "test = data.limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c0e3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T13:38:32.801434Z",
     "start_time": "2022-10-06T13:38:28.346202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 15:38:32 WARN PythonRunner: Detected deadlock while completing task 3.0 in stage 3 (TID 6): Attempting to kill Python Worker\n",
      "22/10/06 15:38:32 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 3 (TID 3): Attempting to kill Python Worker\n",
      "22/10/06 15:38:32 WARN PythonRunner: Detected deadlock while completing task 2.0 in stage 3 (TID 5): Attempting to kill Python Worker\n",
      "22/10/06 15:38:32 WARN PythonRunner: Detected deadlock while completing task 1.0 in stage 3 (TID 4): Attempting to kill Python Worker\n",
      "+--------------------+--------+\n",
      "|                path|category|\n",
      "+--------------------+--------+\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "|dataset/fruits-36...|  Tomato|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "regex = r'(.*)/(.*[a-zA-Z])(.*)/'\n",
    "df = test.withColumn('category', regexp_extract(test.path, regex, 2))\n",
    "df.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
