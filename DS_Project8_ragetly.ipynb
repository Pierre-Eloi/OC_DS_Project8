{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3326124",
   "metadata": {},
   "source": [
    "# Project 8: Deploy a model with a big data architecture in AWS\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "This notebook has been realised to perform a dimension reduction on an image dataset with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525edd1b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-images\" data-toc-modified-id=\"Load-images-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load images</a></span></li><li><span><a href=\"#Create-a-label-column\" data-toc-modified-id=\"Create-a-label-column-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create a label column</a></span></li><li><span><a href=\"#Feature-extraction\" data-toc-modified-id=\"Feature-extraction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-model\" data-toc-modified-id=\"Prepare-model-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Prepare model</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Prepare data</a></span></li><li><span><a href=\"#Define-featurization-in-a-Pandas-UDF\" data-toc-modified-id=\"Define-featurization-in-a-Pandas-UDF-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Define featurization in a Pandas UDF</a></span></li><li><span><a href=\"#Apply-featurization-to-the-DataFrame-of-images\" data-toc-modified-id=\"Apply-featurization-to-the-DataFrame-of-images-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Apply featurization to the DataFrame of images</a></span></li></ul></li><li><span><a href=\"#Add-a-dimensionality-reduction-step\" data-toc-modified-id=\"Add-a-dimensionality-reduction-step-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Add a dimensionality reduction step</a></span><ul class=\"toc-item\"><li><span><a href=\"#Post-processing\" data-toc-modified-id=\"Post-processing-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Post processing</a></span></li><li><span><a href=\"#Scale-data\" data-toc-modified-id=\"Scale-data-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Scale data</a></span></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>PCA</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Pipeline</a></span></li></ul></li><li><span><a href=\"#Save-results\" data-toc-modified-id=\"Save-results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Save results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e14e41",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a47f7f",
   "metadata": {},
   "source": [
    "First, let's import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f74293e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:29.232072Z",
     "start_time": "2023-01-16T14:52:25.387568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 15:52:25.912281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import io\n",
    "from typing import Iterator\n",
    "\n",
    "# Import numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# image preprocessing\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Import deep learning models with tensorflow\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "# Import pyspark library\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, pandas_udf, udf\n",
    "from pyspark.sql.types import ArrayType, StringType, FloatType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import StandardScaler, PCA\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b88d3",
   "metadata": {},
   "source": [
    "Al dataset folder names must be renamed to avoid loading issues with pyspark, all spaces (' ') will be replaced by '_'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de56da9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:29.238316Z",
     "start_time": "2023-01-16T14:52:29.234285Z"
    }
   },
   "outputs": [],
   "source": [
    "def rename_folders(path):\n",
    "    \"\"\"\n",
    "    Change all spaces (' ') by '_' in directory names\n",
    "    to avoid loading issues with pyspark.\n",
    "    \"\"\"\n",
    "    subfolders = [d.path for d in os.scandir(path) if d.is_dir()]\n",
    "    for d in subfolders:\n",
    "        os.rename(d, d.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22fdfb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:29.251621Z",
     "start_time": "2023-01-16T14:52:29.240735Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "local_path = os.path.join(path, 'dataset/local_test')\n",
    "data_path = os.path.join(path, 'dataset/Test')\n",
    "\n",
    "rename_folders(local_path)\n",
    "rename_folders(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4260af2",
   "metadata": {},
   "source": [
    "To finish this setup, let's create a spark session. We will specify:\n",
    "1. an application name\n",
    "2. the app will be executed locally\n",
    "3. a config option enabling to use the parquet format to save results.\n",
    "4. get an existing session or create one if not\n",
    "\n",
    "We will also create a SparkContext from the spark variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f920e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:36.470281Z",
     "start_time": "2023-01-16T14:52:29.255172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/16 15:52:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .appName('DS_P8')\n",
    "                     .master('local')\n",
    "                     .config(\"spark.sql.parquet.writeLegacyFormat\", ('true'))\n",
    "                     .getOrCreate()\n",
    "        )\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10522029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:36.962907Z",
     "start_time": "2023-01-16T14:52:36.472287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://imac.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DS_P8</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12a11e140>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b29f22",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef42fd",
   "metadata": {},
   "source": [
    "Since Spark 2.4, reading image in compressed formats (jpg, png, etc...) is possible with `spark.read.format('image').load('path')`.  \n",
    "The image is read with the ImageIO *Java Library*, and has a special DataFrame schema. The schema contains a StructType Column \"Image\" with all information about reading data.\n",
    "\n",
    "However, data manipulation is much easier by using **binaryFile** format. Instead of creating a unique column *image* including six subcolums,it creates four columns that contain the raw content and metadata of the file:\n",
    "- path: `StringType` *image file path* \n",
    "- modificationTime: `TimestampType` *last modification time of the image*\n",
    "- lenth: `IntegerType` *bytes number of the image*\n",
    "- content: `BinaryType` *image bytes in OpenCV-compatible order (BGR)*\n",
    "\n",
    "The latter will be chosen to avoid multi-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd90adc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:36.968210Z",
     "start_time": "2023-01-16T14:52:36.964994Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    \"\"\"\n",
    "    Load all .jpg images saved in a directory to a binary Spark DataFrame.\n",
    "    \"\"\"\n",
    "    images = spark.read.format(\"binaryFile\") \\\n",
    "        .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "        .option(\"recursiveFileLookup\", \"true\") \\\n",
    "        .load(path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0a718a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:38.267622Z",
     "start_time": "2023-01-16T14:52:36.969942Z"
    }
   },
   "outputs": [],
   "source": [
    "df_img = load_img(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e9e6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:38.298652Z",
     "start_time": "2023-01-16T14:52:38.269525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_img.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796d0a7",
   "metadata": {},
   "source": [
    "## Create a label column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b4374",
   "metadata": {},
   "source": [
    "Here, the label will be the fruit category.  \n",
    "In the dataset we have sometimes different subfolders for the same category (eg. Cherry_1 and Cherry_2), to avoid getting different labels for the same category we will use a regular expression. This one will automatically delete the *_number* at the end if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389f5cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:39.675051Z",
     "start_time": "2023-01-16T14:52:38.301316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+------------+\n",
      "|                path|   modificationTime|length|             content|       label|\n",
      "+--------------------+-------------------+------+--------------------+------------+\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4869|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4865|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4857|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4847|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4847|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4842|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4834|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4824|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4820|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "|file:/Users/pierr...|2021-09-12 19:25:46|  4815|[FF D8 FF E0 00 1...|Apple_Golden|\n",
      "+--------------------+-------------------+------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex = r'(.*)/(.*[a-zA-Z])(.*)/'\n",
    "df_img = df_img.withColumn('label', regexp_extract('path', regex, 2))\n",
    "df_img.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93782b02",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba536e",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1600827",
   "metadata": {},
   "source": [
    "Let's extract image features with transfert learning.\n",
    "\n",
    "We will choose the **MobileNetV2** model. The MobileNetV2 architecture uses [mobile inverted bottleneck convolution (MBConv)](https://towardsdatascience.com/mobilenetv2-inverted-residuals-and-linear-bottlenecks-8a4362f4ffd5), which enables to deliver high accuracy while keeping the parameters and mathematical operations as low as possible. Residual blocks connect the beginning and end of a convolutional block with a skip connection.\n",
    "\n",
    "MobileNetV2 follows a narrow->wide->narrow approach, which is the inversion of the original residual Block (explaining the \"inverted\" word). The first step widens the network by a factor 6 using a 1x1 convolution, the following 3x3 depthwise convolution greatly reduces the number of parameters. Afterwards another 1x1 convolution squeezes the network to match the initial number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c98a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.217109Z",
     "start_time": "2023-01-16T14:52:39.682016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 15:52:39.702178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e06c7",
   "metadata": {},
   "source": [
    "As shown above, the output dimension will be (7, 7, 1280), meaning **62'720** features.\n",
    "\n",
    "The model weights will be saved in **Broadcast variables** to reduce communication costs. \n",
    "Broadcast variables are read-only shared variables, they are cached and available on all nodes in a cluster to be accessed or used by the tasks. Instead sending this data along with every task, spark distributes broadcast variables to the machine using efficient broadcast algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7debc71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.367787Z",
     "start_time": "2023-01-16T14:52:41.218861Z"
    }
   },
   "outputs": [],
   "source": [
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6182c19c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.372565Z",
     "start_time": "2023-01-16T14:52:41.369593Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed\n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c73a3",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec445e",
   "metadata": {},
   "source": [
    "As other CNN models (ResNet50, InceptionV3, VGG16,etc...), the MobileNetV2 model expects (224, 224, 3) input images. All images of the dataset have a (100, 100, 3) dimension and so, must be reshaped before using the model. We will also add MobileNetV2 specific preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d7a858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.377136Z",
     "start_time": "2023-01-16T14:52:41.374189Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_img(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7237f",
   "metadata": {},
   "source": [
    "### Define featurization in a Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a57c4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.381973Z",
     "start_time": "2023-01-16T14:52:41.378864Z"
    }
   },
   "outputs": [],
   "source": [
    "def featurize_series(model, series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the MobileNetV2 model.\n",
    "    For some layers, output features will be multi-dimensional tensors.\n",
    "    Feature tensors are flattened to vectors for easier storage in Spark DataFrames.\n",
    "    -----------    \n",
    "    Return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(series.map(preprocess_img))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb48abe",
   "metadata": {},
   "source": [
    "We will use an iterator UDF, this pandas UDF is useful when the UDF execution requires initializing some state, as loading a machine learning model to apply inference to every input batch, which is the case here.\n",
    "\n",
    "As explained in the [spark documentation](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html), it is preferred to specify type hints for the pandas UDF instead of specifying pandas UDF type via *functionType* which will be deprecated in the future releases. We will specify the Python type hint as `Iterator[pandas.Series] -> Iterator[pandas.Series]`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f65640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.486067Z",
     "start_time": "2023-01-16T14:52:41.383941Z"
    }
   },
   "outputs": [],
   "source": [
    "@pandas_udf('array<float>')\n",
    "def featurize_udf(batch_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column\n",
    "    of type ArrayType(FloatType).\n",
    "    With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    for multiple data batches.\n",
    "    This amortizes the overhead of loading big models.\n",
    "    \"\"\"\n",
    "    model = model_fn()\n",
    "    for s in batch_iter:\n",
    "        yield featurize_series(model, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5141c7",
   "metadata": {},
   "source": [
    "### Apply featurization to the DataFrame of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5da10",
   "metadata": {},
   "source": [
    "Pandas UDFs on large records (e.g., very large images) can run into Out Of Memory (OOM) errors. It can be avoided by reducing the Arrow batch size via `maxRecordsPerBatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b29aa59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:41.491758Z",
     "start_time": "2023-01-16T14:52:41.488176Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27303cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:49.223736Z",
     "start_time": "2023-01-16T14:52:41.493940Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 15:52:43.085166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 15:52:46.297311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+\n",
      "|                path|       label|            features|\n",
      "+--------------------+------------+--------------------+\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_features = df_img.select('path',\n",
    "                            'label',\n",
    "                            featurize_udf('content').alias('features')\n",
    "                           )\n",
    "\n",
    "df_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62719f79",
   "metadata": {},
   "source": [
    "## Add a dimensionality reduction step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e827a8",
   "metadata": {},
   "source": [
    "**Principal Component Analysis** (PCA) is by far the most popular dimensionality reduction algorithm. We will use this one to reduce our 62'720 features to **1'500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af30216",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1adc7b5",
   "metadata": {},
   "source": [
    "Spark MLlib required vector type column and not array one. In Spark, the type for vector is *VectorUDT*. This type can be directly used with UDF function but not with PandasUDF where an array type must be used instead. A new udf function will be created to perform the convertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4776adcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:49.229213Z",
     "start_time": "2023-01-16T14:52:49.225314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4de37f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:57.673106Z",
     "start_time": "2023-01-16T14:52:49.230801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 15:52:49.987547: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 15:52:53.117175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+\n",
      "|                path|       label|            features|\n",
      "+--------------------+------------+--------------------+\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0,0.0,0.0,0.0,...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0,0.0,0.0,0.0,...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0,0.0,0.0,0.0,...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0,0.0,0.0,0.0,...|\n",
      "|file:/Users/pierr...|Apple_Golden|[0.0,0.0,0.0,0.0,...|\n",
      "+--------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "arr_to_vec_udf = udf(lambda a: Vectors.dense(a), VectorUDT())\n",
    "\n",
    "df_vec = df_features.select(\n",
    "    'path',\n",
    "    'label',\n",
    "    arr_to_vec_udf('features').alias('features'))\n",
    "df_vec.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bee17ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:57.677860Z",
     "start_time": "2023-01-16T14:52:57.674807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vec.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a609e98",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5128a",
   "metadata": {},
   "source": [
    "PCA assumes that the dataset is centered around the origin. We will use the StandardScaler to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4af2f10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:57.692841Z",
     "start_time": "2023-01-16T14:52:57.679606Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='features',\n",
    "                        outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd259e2",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88afb9c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T14:52:57.702770Z",
     "start_time": "2023-01-16T14:52:57.694597Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(k=1000, inputCol='scaled_features', outputCol='pca_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327ff69",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d0d8b",
   "metadata": {},
   "source": [
    "Let's combine previous steps into a pipeline. This step cannot be run locally due to OOM issues, a cluster must be created first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0ab08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T17:56:10.004862Z",
     "start_time": "2023-01-12T17:56:10.004833Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[scaler, pca])\n",
    "pipeline_model = pipeline.fit(df_vec)\n",
    "result = pipeline_model.transform(df_vec).select('path', 'label', 'pca_features')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d6c06",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede2c78",
   "metadata": {},
   "source": [
    "Results will be saved using the parquet format for performance purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec76cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T17:55:23.895789Z",
     "start_time": "2023-01-12T17:55:23.895745Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_df.write.mode(\"overwrite\").parquet('dataset/results/data_parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
