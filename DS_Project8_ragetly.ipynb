{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3326124",
   "metadata": {},
   "source": [
    "# Project 8: Deploy a model with a big data architecture in AWS\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "This notebook has been realised to perform a dimension reduction on an image dataset with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525edd1b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-images\" data-toc-modified-id=\"Load-images-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load images</a></span></li><li><span><a href=\"#Create-a-label-column\" data-toc-modified-id=\"Create-a-label-column-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create a label column</a></span></li><li><span><a href=\"#Feature-extraction\" data-toc-modified-id=\"Feature-extraction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-model\" data-toc-modified-id=\"Prepare-model-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Prepare model</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Prepare data</a></span></li><li><span><a href=\"#Define-featurization-in-a-Pandas-UDF\" data-toc-modified-id=\"Define-featurization-in-a-Pandas-UDF-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Define featurization in a Pandas UDF</a></span></li><li><span><a href=\"#Apply-featurization-to-the-DataFrame-of-images\" data-toc-modified-id=\"Apply-featurization-to-the-DataFrame-of-images-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Apply featurization to the DataFrame of images</a></span></li></ul></li><li><span><a href=\"#Add-a-dimensionality-reduction-step\" data-toc-modified-id=\"Add-a-dimensionality-reduction-step-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Add a dimensionality reduction step</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sparse-random-projection\" data-toc-modified-id=\"Sparse-random-projection-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Sparse random projection</a></span></li></ul></li><li><span><a href=\"#Save-results\" data-toc-modified-id=\"Save-results-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Save results</a></span></li><li><span><a href=\"#Load-parquet-data\" data-toc-modified-id=\"Load-parquet-data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Load parquet data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e14e41",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a47f7f",
   "metadata": {},
   "source": [
    "First, let's import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f74293e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:15.908685Z",
     "start_time": "2023-01-28T11:49:11.037979Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 12:49:11.693166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import io\n",
    "from typing import Iterator\n",
    "\n",
    "# Import numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# image preprocessing\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Import deep learning models with tensorflow\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "# Import pyspark library\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, pandas_udf, udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import StandardScaler, PCA\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b88d3",
   "metadata": {},
   "source": [
    "Al dataset folder names must be renamed to avoid loading issues with pyspark, all spaces (' ') will be replaced by '_'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de56da9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:15.914530Z",
     "start_time": "2023-01-28T11:49:15.911136Z"
    }
   },
   "outputs": [],
   "source": [
    "def rename_folders(path):\n",
    "    \"\"\"\n",
    "    Change all spaces (' ') by '_' in directory names\n",
    "    to avoid loading issues with pyspark.\n",
    "    \"\"\"\n",
    "    subfolders = [d.path for d in os.scandir(path) if d.is_dir()]\n",
    "    for d in subfolders:\n",
    "        os.rename(d, d.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22fdfb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:15.927898Z",
     "start_time": "2023-01-28T11:49:15.916641Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "local_path = os.path.join(path, 'dataset/local_test')\n",
    "data_path = os.path.join(path, 'dataset/Test')\n",
    "\n",
    "rename_folders(local_path)\n",
    "rename_folders(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4260af2",
   "metadata": {},
   "source": [
    "To finish this setup, let's create a spark session. We will specify:\n",
    "1. an application name\n",
    "2. the app will be executed locally\n",
    "3. a config option enabling to use the parquet format to save results.\n",
    "4. get an existing session or create one if not\n",
    "\n",
    "We will also create a SparkContext from the spark variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f920e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:23.703733Z",
     "start_time": "2023-01-28T11:49:15.931163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/28 12:49:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .appName('DS_P8')\n",
    "                     .master('local')\n",
    "                     .config(\"spark.sql.parquet.writeLegacyFormat\", ('true'))\n",
    "                     .getOrCreate()\n",
    "        )\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10522029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:24.319738Z",
     "start_time": "2023-01-28T11:49:23.705993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://imac.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DS_P8</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13eeb3e80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b29f22",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef42fd",
   "metadata": {},
   "source": [
    "Since Spark 2.4, reading image in compressed formats (jpg, png, etc...) is possible with `spark.read.format('image').load('path')`.  \n",
    "The image is read with the ImageIO *Java Library*, and has a special DataFrame schema. The schema contains a StructType Column \"Image\" with all information about reading data.\n",
    "\n",
    "However, data manipulation is much easier by using **binaryFile** format. Instead of creating a unique column *image* including six subcolums,it creates four columns that contain the raw content and metadata of the file:\n",
    "- path: `StringType` *image file path* \n",
    "- modificationTime: `TimestampType` *last modification time of the image*\n",
    "- lenth: `IntegerType` *bytes number of the image*\n",
    "- content: `BinaryType` *image bytes in OpenCV-compatible order (BGR)*\n",
    "\n",
    "The latter will be chosen to avoid multi-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd90adc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:24.326006Z",
     "start_time": "2023-01-28T11:49:24.322129Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    \"\"\"\n",
    "    Load all .jpg images saved in a directory to a binary Spark DataFrame.\n",
    "    \"\"\"\n",
    "    images = spark.read.format(\"binaryFile\") \\\n",
    "        .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "        .option(\"recursiveFileLookup\", \"true\") \\\n",
    "        .load(path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0a718a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:25.683469Z",
     "start_time": "2023-01-28T11:49:24.328349Z"
    }
   },
   "outputs": [],
   "source": [
    "df_img = load_img(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e9e6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:25.706263Z",
     "start_time": "2023-01-28T11:49:25.685333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_img.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d759fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:26.429509Z",
     "start_time": "2023-01-28T11:49:25.708791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d462f303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:27.567880Z",
     "start_time": "2023-01-28T11:49:26.434046Z"
    }
   },
   "outputs": [],
   "source": [
    "n_img = df_img.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796d0a7",
   "metadata": {},
   "source": [
    "## Create a label column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b4374",
   "metadata": {},
   "source": [
    "Here, the label will be the fruit category.  \n",
    "In the dataset we have sometimes different subfolders for the same category (eg. Cherry_1 and Cherry_2), to avoid getting different labels for the same category we will use a regular expression. This one will automatically delete the *_number* at the end if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389f5cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:27.605800Z",
     "start_time": "2023-01-28T11:49:27.569618Z"
    }
   },
   "outputs": [],
   "source": [
    "regex = r'(.*)/(.*[a-zA-Z])(.*)/'\n",
    "df_img = df_img.withColumn('label', regexp_extract('path', regex, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93782b02",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba536e",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1600827",
   "metadata": {},
   "source": [
    "Let's extract image features with transfert learning.\n",
    "\n",
    "We will choose the **MobileNetV2** model. The MobileNetV2 architecture uses [mobile inverted bottleneck convolution (MBConv)](https://towardsdatascience.com/mobilenetv2-inverted-residuals-and-linear-bottlenecks-8a4362f4ffd5), which enables to deliver high accuracy while keeping the parameters and mathematical operations as low as possible. Residual blocks connect the beginning and end of a convolutional block with a skip connection.\n",
    "\n",
    "MobileNetV2 follows a narrow->wide->narrow approach, which is the inversion of the original residual Block (explaining the \"inverted\" word). The first step widens the network by a factor 6 using a 1x1 convolution, the following 3x3 depthwise convolution greatly reduces the number of parameters. Afterwards another 1x1 convolution squeezes the network to match the initial number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c98a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:28.922195Z",
     "start_time": "2023-01-28T11:49:27.607503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 12:49:27.624368: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                       include_top=False,\n",
    "                       input_shape=(224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e06c7",
   "metadata": {},
   "source": [
    "As shown above, the output dimension will be (7, 7, 1280), meaning **62'720** features.\n",
    "\n",
    "The model weights will be saved in **Broadcast variables** to reduce communication costs. \n",
    "Broadcast variables are read-only shared variables, they are cached and available on all nodes in a cluster to be accessed or used by the tasks. Instead sending this data along with every task, spark distributes broadcast variables to the machine using efficient broadcast algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7debc71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:29.069237Z",
     "start_time": "2023-01-28T11:49:28.923787Z"
    }
   },
   "outputs": [],
   "source": [
    "bc_model_weights = sc.broadcast(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6182c19c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:29.074353Z",
     "start_time": "2023-01-28T11:49:29.071222Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed\n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c73a3",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec445e",
   "metadata": {},
   "source": [
    "As other CNN models (ResNet50, InceptionV3, VGG16,etc...), the MobileNetV2 model expects (224, 224, 3) input images. All images of the dataset have a (100, 100, 3) dimension and so, must be reshaped before using the model. We will also add MobileNetV2 specific preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d7a858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:29.079584Z",
     "start_time": "2023-01-28T11:49:29.076402Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_img(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7237f",
   "metadata": {},
   "source": [
    "### Define featurization in a Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a57c4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:29.084527Z",
     "start_time": "2023-01-28T11:49:29.081415Z"
    }
   },
   "outputs": [],
   "source": [
    "def featurize_series(model, series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the MobileNetV2 model.\n",
    "    For some layers, output features will be multi-dimensional tensors.\n",
    "    Feature tensors are flattened to vectors for easier storage in Spark DataFrames.\n",
    "    -----------    \n",
    "    Return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    X = np.stack(series.map(preprocess_img))\n",
    "    preds = model.predict(X)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb48abe",
   "metadata": {},
   "source": [
    "We will use an iterator UDF, this pandas UDF is useful when the UDF execution requires initializing some state, as loading a machine learning model to apply inference to every input batch, which is the case here.\n",
    "\n",
    "As explained in the [spark documentation](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html), it is preferred to specify type hints for the pandas UDF instead of specifying pandas UDF type via *functionType* which will be deprecated in the future releases. We will specify the Python type hint as `Iterator[pandas.Series] -> Iterator[pandas.Series]`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68f65640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:29.184295Z",
     "start_time": "2023-01-28T11:49:29.086348Z"
    }
   },
   "outputs": [],
   "source": [
    "@pandas_udf('array<float>')\n",
    "def featurize_udf(batch_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column\n",
    "    of type ArrayType(FloatType).\n",
    "    With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    for multiple data batches.\n",
    "    This amortizes the overhead of loading big models.\n",
    "    \"\"\"\n",
    "    model = model_fn()\n",
    "    for s in batch_iter:\n",
    "        yield featurize_series(model, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5141c7",
   "metadata": {},
   "source": [
    "### Apply featurization to the DataFrame of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27303cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:29.233609Z",
     "start_time": "2023-01-28T11:49:29.186016Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features = df_img.select('label',\n",
    "                            featurize_udf('content').alias('features')\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62719f79",
   "metadata": {},
   "source": [
    "## Add a dimensionality reduction step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8cc84a",
   "metadata": {},
   "source": [
    "### Sparse random projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e827a8",
   "metadata": {},
   "source": [
    "**Principal Component Analysis** (PCA) is by far the most popular dimensionality reduction algorithm.  \n",
    "However, it may fail when  the number of features is high &ndash; which is the case here. The reason is the covariance matrix itself will not fit into memory. For instance, with 7 x 7 x 1280 = **62'720 features**, it results a 62'720 x 62'720 x 8 ~ **31.5Gb** covariance matrix! So we need a other technique to reduce dimensions.\n",
    "\n",
    "For doing it, we will use the **Sparse random projection**. In short, if you have dataset X of size n x m, you can multiply it by some sparse random matrix R of size m x k (with k << m) and obtain new matrix X' of a much smaller size n x k. To get R, only the following values parameters are required:\n",
    "- the number of features $m$ (automatically calculated when using the fit( ) method)\n",
    "- the number of components $k$ (we will use the **Johnson-Lindenstrauss lemma**)\n",
    "\n",
    "Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9db58bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:44.249535Z",
     "start_time": "2023-01-28T11:49:29.235177Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 12:49:31.317987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-28 12:49:34.516162: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "n_features = len(df_features.first()['features'])\n",
    "k = johnson_lindenstrauss_min_dim(n_features, eps=0.1)\n",
    "# Create a sparse dummy array to fit the sparse random projection\n",
    "# It enables to broadcast the fitted sparse random projection\n",
    "dummy_X = scipy.sparse.csr_matrix((n_img, n_features), dtype=np.float32)\n",
    "srp = SparseRandomProjection(n_components=k, random_state=42)\n",
    "srp.fit(dummy_X)\n",
    "bc_srp = sc.broadcast(srp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe2e9b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:44.254169Z",
     "start_time": "2023-01-28T11:49:44.251531Z"
    }
   },
   "outputs": [],
   "source": [
    "def dim_red_series(model, series):\n",
    "    \"\"\"\n",
    "    Reduce the dimension of a pd.Series of features using Sparse Random Projection.\n",
    "    -----------    \n",
    "    Return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    X = np.stack(series)\n",
    "    X_tr = model.transform(X)\n",
    "    return pd.Series(X_tr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8a42963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:44.267392Z",
     "start_time": "2023-01-28T11:49:44.255940Z"
    }
   },
   "outputs": [],
   "source": [
    "@pandas_udf('array<float>')\n",
    "def reduce_udf(batch_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"This method is a Scalar Iterator pandas UDF\n",
    "    wrapping our dimensionality reduction function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column\n",
    "    of type ArrayType(FloatType).\n",
    "    With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    for multiple data batches.\n",
    "    This amortizes the overhead of loading big models.\n",
    "    \"\"\"\n",
    "    model = bc_srp.value\n",
    "    for s in batch_iter:\n",
    "        yield dim_red_series(model, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55140467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:50.701208Z",
     "start_time": "2023-01-28T11:49:44.269009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 12:49:44.932550: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/pierre-eloiragetly/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SparseRandomProjection from version 1.2.1 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2023-01-28 12:49:48.326499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9468"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df_features.select('label',\n",
    "                            reduce_udf('features').alias('srp_features')\n",
    "                           )\n",
    "\n",
    "len(result.first()['srp_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d2a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:27:45.230567Z",
     "start_time": "2023-01-28T11:27:45.228128Z"
    }
   },
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb36295",
   "metadata": {},
   "source": [
    "Results will be saved using the parquet format for performance purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41afb63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:49:50.706085Z",
     "start_time": "2023-01-28T11:49:50.703502Z"
    }
   },
   "outputs": [],
   "source": [
    "result_path = os.path.join(path, 'dataset/results/data_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad3a2bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:51:10.172914Z",
     "start_time": "2023-01-28T11:49:50.708632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 12:49:51.421312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/pierre-eloiragetly/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SparseRandomProjection from version 1.2.1 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2023-01-28 12:49:54.666673: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step                  (1 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                  (2 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                  (3 + 1) / 31]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x113120dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x11322dbd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step                  (6 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                  (7 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                  (8 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                  (9 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (10 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (11 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (12 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (13 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (14 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (15 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (16 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (17 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (18 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (19 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (20 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step                 (21 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step>                (22 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step==>              (23 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step====>            (24 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step=====>           (25 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step=======>         (26 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step=========>       (27 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step===========>     (28 + 1) / 31]\n",
      "1/1 [==============================] - 1s 1s/step=============>   (29 + 1) / 31]\n",
      "1/1 [==============================] - 1s 845ms/step============> (30 + 1) / 31]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.repartition(1).write.mode(\"overwrite\").parquet(result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b419d2e",
   "metadata": {},
   "source": [
    "## Load parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b809c343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-28T11:52:01.787197Z",
     "start_time": "2023-01-28T11:52:01.562966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>srp_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple_Golden</td>\n",
       "      <td>[-3.2093186, 1.396389, 9.263401, -0.4009514, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple_Golden</td>\n",
       "      <td>[-3.871591, 0.19321874, 7.828599, -0.7790657, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple_Golden</td>\n",
       "      <td>[-1.8690182, 1.2320036, 8.495892, -0.560804, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple_Golden</td>\n",
       "      <td>[-2.9468348, 0.66861093, 7.8678336, -0.5279124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple_Golden</td>\n",
       "      <td>[-2.7231698, 1.4083207, 8.18139, 0.07034999, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                       srp_features\n",
       "0  Apple_Golden  [-3.2093186, 1.396389, 9.263401, -0.4009514, -...\n",
       "1  Apple_Golden  [-3.871591, 0.19321874, 7.828599, -0.7790657, ...\n",
       "2  Apple_Golden  [-1.8690182, 1.2320036, 8.495892, -0.560804, -...\n",
       "3  Apple_Golden  [-2.9468348, 0.66861093, 7.8678336, -0.5279124...\n",
       "4  Apple_Golden  [-2.7231698, 1.4083207, 8.18139, 0.07034999, -..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(result_path, engine='pyarrow')\n",
    "df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
