{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3326124",
   "metadata": {},
   "source": [
    "# Project 8: Deploy a model with a big data architecture in AWS\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "This notebook has been realised to perform a dimension reduction on an image dataset with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525edd1b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-images\" data-toc-modified-id=\"Load-images-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load images</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-all-subfolders\" data-toc-modified-id=\"Get-all-subfolders-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Get all subfolders</a></span></li><li><span><a href=\"#Create-a-DataFrame-with-all-images\" data-toc-modified-id=\"Create-a-DataFrame-with-all-images-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Create a DataFrame with all images</a></span></li></ul></li><li><span><a href=\"#Create-a-Category-column\" data-toc-modified-id=\"Create-a-Category-column-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create a Category column</a></span></li><li><span><a href=\"#Feature-extraction\" data-toc-modified-id=\"Feature-extraction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Feature extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-model\" data-toc-modified-id=\"Prepare-model-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Prepare model</a></span></li><li><span><a href=\"#Prepare-data\" data-toc-modified-id=\"Prepare-data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Prepare data</a></span></li><li><span><a href=\"#Define-featurization-in-a-Pandas-UDF\" data-toc-modified-id=\"Define-featurization-in-a-Pandas-UDF-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Define featurization in a Pandas UDF</a></span></li><li><span><a href=\"#Apply-featurization-to-the-DataFrame-of-images\" data-toc-modified-id=\"Apply-featurization-to-the-DataFrame-of-images-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Apply featurization to the DataFrame of images</a></span></li></ul></li><li><span><a href=\"#Save-results\" data-toc-modified-id=\"Save-results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Save results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e14e41",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a47f7f",
   "metadata": {},
   "source": [
    "First, let's import a common modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f74293e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:11.204683Z",
     "start_time": "2023-01-06T07:51:06.708849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 08:51:07.346007: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "# Import numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# image preprocessing\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Import deep learning models with tensorflow\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "# Import pyspark library\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, pandas_udf\n",
    "from pyspark.sql.types import ArrayType, StringType, FloatType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4260af2",
   "metadata": {},
   "source": [
    "Let's create a spark session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f920e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:18.994650Z",
     "start_time": "2023-01-06T07:51:11.207059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/06 08:51:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "sc.setLogLevel(\"Warn\")\n",
    "spark = SparkSession.builder.appName('ImageReduction').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b29f22",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7b80f",
   "metadata": {},
   "source": [
    "### Get all subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc56aed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:19.005164Z",
     "start_time": "2023-01-06T07:51:18.996564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/sample_dataset/Kiwi',\n",
       " 'dataset/sample_dataset/Apple_Golden_3',\n",
       " 'dataset/sample_dataset/Cherry_1',\n",
       " 'dataset/sample_dataset/Eggplant',\n",
       " 'dataset/sample_dataset/Banana']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = 'dataset/sample_dataset'\n",
    "subfolders = [d.path for d in os.scandir(root_path) if d.is_dir()]\n",
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e158bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:19.011361Z",
     "start_time": "2023-01-06T07:51:19.008260Z"
    }
   },
   "outputs": [],
   "source": [
    "# change all spaces (' ') by '_' in directory names\n",
    "# to avoid loading issues with pyspark\n",
    "for d in subfolders:\n",
    "    os.rename(d, d.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e52ad",
   "metadata": {},
   "source": [
    "### Create a DataFrame with all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef42fd",
   "metadata": {},
   "source": [
    "Since Spark 2.4, reading image in compressed formats (jpg, png, etc...) is possible with `spark.read.format('image').load('path')`.  \n",
    "The image is read with the ImageIO *Java Library*, and has a special DataFrame schema. The schema contains a StructType Column \"Image\" with all information about reading data.\n",
    "\n",
    "However, data manipulation is much easier by using **binaryFile** format. Instead of creating a unique column *image* including six subcolums,it creates four columns that contain the raw content and metadata of the file:\n",
    "- path: `StringType` *image file path* \n",
    "- modificationTime: `TimestampType` *last modification time of the image*\n",
    "- lenth: `IntegerType` *bytes number of the image*\n",
    "- content: `BinaryType` *image bytes in OpenCV-compatible order (BGR)*\n",
    "\n",
    "The latter will be chosen to avoid multi-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd90adc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:19.016326Z",
     "start_time": "2023-01-06T07:51:19.013311Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_img(dir_path):\n",
    "    \"\"\"\n",
    "    Load all .jpg images saved in a directory to a binary Spark DataFrame.\n",
    "    \"\"\"\n",
    "    images = spark.read.format(\"binaryFile\") \\\n",
    "        .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "        .option(\"recursiveFileLookup\", \"true\") \\\n",
    "        .load(dir_path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397f29f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:21.236601Z",
     "start_time": "2023-01-06T07:51:19.018593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load images\n",
    "dataframes =[load_img(dir_path) for dir_path in subfolders]\n",
    "\n",
    "# merge DataFrames\n",
    "image_df = reduce(lambda first, second: first.union(second), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e9e6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:21.248534Z",
     "start_time": "2023-01-06T07:51:21.238360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796d0a7",
   "metadata": {},
   "source": [
    "## Create a Category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389f5cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:22.931528Z",
     "start_time": "2023-01-06T07:51:21.250704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+--------+\n",
      "|                path|   modificationTime|length|             content|category|\n",
      "+--------------------+-------------------+------+--------------------+--------+\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5380|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5378|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5344|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5336|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5330|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5328|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5327|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5326|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5312|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "|file:/Users/pierr...|2021-09-12 19:26:18|  5307|[FF D8 FF E0 00 1...|    Kiwi|\n",
      "+--------------------+-------------------+------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex = r'(.*)/(.*[a-zA-Z])(.*)/'\n",
    "df = image_df.withColumn('category', regexp_extract('path', regex, 2))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93782b02",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba536e",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1600827",
   "metadata": {},
   "source": [
    "The **InceptionV3** model will be used to extract features from images.\n",
    "\n",
    "The model weights will be saved in **Broadcast variables** to reduce communication costs. \n",
    "Broadcast variables are read-only shared variables, they are cached and available on all nodes in a cluster to be accessed or used by the tasks. Instead sending this data along with every task, spark distributes broadcast variables to the machine using efficient broadcast algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6182c19c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:25.530713Z",
     "start_time": "2023-01-06T07:51:22.933587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 08:51:22.951717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3(include_top=False)\n",
    "bc_model_weights = sc.broadcast(model.get_weights())\n",
    "\n",
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns an InceptionV3 model with top layer removed\n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = InceptionV3(weights=None, include_top=False)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c73a3",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d7a858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:25.540114Z",
     "start_time": "2023-01-06T07:51:25.536222Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_img(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7237f",
   "metadata": {},
   "source": [
    "### Define featurization in a Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f65640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:25.659962Z",
     "start_time": "2023-01-06T07:51:25.543575Z"
    }
   },
   "outputs": [],
   "source": [
    "@pandas_udf('array<float>')\n",
    "def featurize_udf(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the inceptionV3 model.\n",
    "    For some layers, output features will be multi-dimensional tensors.\n",
    "    Feature tensors are flattened to vectors for easier storage in Spark DataFrames.\n",
    "    -----------    \n",
    "    Return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    model = model_fn()\n",
    "    arr = np.stack(s.map(preprocess_img))\n",
    "    preds = model.predict(arr)\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81aaf64",
   "metadata": {},
   "source": [
    "As explained in the [spark documentation](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.pandas_udf.html), it is preferred to specify type hints for the pandas UDF instead of specifying pandas UDF type via *functionType* which will be deprecated in the future releases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5141c7",
   "metadata": {},
   "source": [
    "### Apply featurization to the DataFrame of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5da10",
   "metadata": {},
   "source": [
    "Pandas UDFs on large records (e.g., very large images) can run into Out Of Memory (OOM) errors. It can be avoided by reducing the Arrow batch size via `maxRecordsPerBatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b29aa59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:25.666816Z",
     "start_time": "2023-01-06T07:51:25.661998Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27303cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:51:36.305645Z",
     "start_time": "2023-01-06T07:51:25.668943Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 08:51:27.652185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:31.730731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+\n",
      "|                path|category|             content|            features|\n",
      "+--------------------+--------+--------------------+--------------------+\n",
      "|file:/Users/pierr...|    Kiwi|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|    Kiwi|[FF D8 FF E0 00 1...|[0.0, 0.01969701,...|\n",
      "|file:/Users/pierr...|    Kiwi|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|    Kiwi|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
      "|file:/Users/pierr...|    Kiwi|[FF D8 FF E0 00 1...|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_df = df.withColumn('features', featurize_udf('content')) \\\n",
    "                .select('path', 'category', 'content', 'features')\n",
    "\n",
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d6c06",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede2c78",
   "metadata": {},
   "source": [
    "Results will be saved using the parquet format for performance purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2142ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T07:53:38.201615Z",
     "start_time": "2023-01-06T07:51:36.307829Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 08:51:37.574433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:37.587907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:37.616056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:37.631038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:37.637999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:37.641644: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:43.571715: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:43.571879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:43.572410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:43.573015: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:43.572990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 08:51:43.574976: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step                  (6 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 5s 5s/step                 (12 + 6) / 78]\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 4s 4s/step                 (18 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1112a9900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1112e1900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1112bd900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1112a5900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1112d9900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1112a5900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1113e7130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1113e7130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1113e7130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1113e7130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1113e7130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1113e7130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step                 (36 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step                 (37 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step                 (42 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step                 (43 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step                 (44 + 6) / 78]\n",
      "1/1 [==============================] - 3s 3s/step                 (48 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step                 (49 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step                 (54 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step>                (55 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step=>               (57 + 6) / 78]\n",
      "1/1 [==============================] - 3s 3s/step===>             (60 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step====>            (61 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step======>          (64 + 6) / 78]\n",
      "1/1 [==============================] - 3s 3s/step========>        (66 + 6) / 78]\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step========>        (67 + 6) / 78]\n",
      "1/1 [==============================] - 5s 5s/step=========>       (68 + 6) / 78]\n",
      "1/1 [==============================] - 3s 3s/step============>    (72 + 6) / 78]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step=============>   (73 + 5) / 78]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_df.write.mode(\"overwrite\").parquet(\"dataset/prep_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
